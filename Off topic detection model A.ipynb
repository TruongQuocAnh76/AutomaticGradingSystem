{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12976, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "DATASET_DIR = './data/'\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "SAVE_DIR = './'\n",
    "\n",
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "X = X.dropna(axis=1)\n",
    "X = X.drop(columns=['rater1_domain1', 'rater2_domain1', 'domain1_score', 'essay_id'])\n",
    "prompt = X['essay_set']\n",
    "# X = X.drop(columns=['essay_set'])\n",
    "y = open(os.path.join(DATASET_DIR, 'prompt.txt')).read().splitlines()\n",
    "print(len(y))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def essay_to_wordlist(essay_v, remove_stopwords):\n",
    "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
    "    words = essay_v.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)\n",
    "\n",
    "def essay_to_sentences(essay_v, remove_stopwords):\n",
    "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
    "    # featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    # num_words = 0.\n",
    "    # index2word_set = set(model.wv.index_to_key)\n",
    "    # for word in words:\n",
    "    #     if word in index2word_set:\n",
    "    #         num_words += 1\n",
    "    #         featureVec = np.add(featureVec,model.wv[word])        \n",
    "    # featureVec = np.divide(featureVec,num_words)\n",
    "    # return featureVec\n",
    "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if word in model:\n",
    "            nwords += 1\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "            \n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in y:\n",
    "  sentences += essay_to_sentences(i, remove_stopwords = True)\n",
    "\n",
    "for essay in X['essay']:\n",
    "  sentences += essay_to_sentences(essay, remove_stopwords = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "num_features = 300 \n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "# print(\"Training Word2Vec Model...\")\n",
    "# model = Word2Vec(sentences, workers=num_workers, vector_size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "# model.init_sims(replace=True)\n",
    "# model.save('./w2v_otd.model')\n",
    "\n",
    "# model = Word2Vec.load(\"./mysite/grader/deep_learning_files/word2vecmodel.model\")\n",
    "import gensim.downloader as api\n",
    "model = api.load(\"word2vec-google-news-300\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_essays = []\n",
    "# for essay_v in X['essay']:\n",
    "#     clean_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
    "# data_vecs = getAvgFeatureVecs(clean_essays, model, num_features)\n",
    "# # save it to csv\n",
    "# df = pd.DataFrame(data_vecs)\n",
    "# df.to_csv(os.path.join(SAVE_DIR, 'data_vecs.csv'), index=False)\n",
    "\n",
    "# load datavecs\n",
    "data_vecs = pd.read_csv(os.path.join(SAVE_DIR, 'data_vecs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_z_scores(cosine_similarities, mean, std_dev):\n",
    "    \"\"\"Calculate the z-scores based on cosine similarities.\"\"\"\n",
    "    return (cosine_similarities - mean) / std_dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "X_train, X_valid, y_train, y_valid= train_test_split(data_vecs, prompt, test_size=0.1, random_state=42)\n",
    "y_valid = np.array(y_valid)\n",
    "# standardize\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss = StandardScaler()\n",
    "# X_train = ss.fit_transform(X_train)\n",
    "# X_valid = ss.transform(X_valid)\n",
    "# joblib.dump(ss, os.path.join(SAVE_DIR, 'ss.pkl'))\n",
    "\n",
    "# shuffle y_valid to create off topic records\n",
    "true = y_valid.copy()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(y_valid)\n",
    "\n",
    "true = [1 if true[i] == y_valid[i] else 0 for i in range(y_valid.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_sentences = []\n",
    "# for i in y:\n",
    "#   y_sentences.append(essay_to_wordlist(i, remove_stopwords = True))\n",
    "# prompt_vector = getAvgFeatureVecs(y_sentences, model, num_features)\n",
    "# # save it for later use in csv\n",
    "# prompt_vector = pd.DataFrame(prompt_vector)\n",
    "# prompt_vector.to_csv(os.path.join(SAVE_DIR, 'prompt_vector.csv'), index=False)\n",
    "\n",
    "prompt_vector = np.array(pd.read_csv(os.path.join(SAVE_DIR, 'prompt_vector.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed prompt sentences\n",
    "\n",
    "train_essays = data_vecs\n",
    "\n",
    "# cos similarities between each training essays with the training set\n",
    "cosine_similarities1 = cosine_similarity(X_train, X_train)\n",
    "max_cos_sim1 = np.max(cosine_similarities1, axis = 1)\n",
    "# cos similarity between training essays and its corresponding prompt\n",
    "prompt_similarities = np.diag(cosine_similarity(X_train, prompt_vector[y_train - 1]))\n",
    "\n",
    "# z score parameters\n",
    "mean_max_cos_sim = np.mean(max_cos_sim1)\n",
    "std_dev_max_cos_sim = np.std(max_cos_sim1)\n",
    "\n",
    "mean_prompt_cos = np.mean(prompt_similarities)\n",
    "std_dev_prompt_cos = np.std(prompt_similarities)\n",
    "\n",
    "def modelA(novel_essays, novel_essays_prompt):\n",
    "  '''\n",
    "  predict off-topicity using cosine similarity and z-scores\n",
    "  '''\n",
    "  # cos similarity between novel essay and training essays\n",
    "  cosine_similarities = cosine_similarity(novel_essays, X_train)\n",
    "  max_cos_sim = np.max(cosine_similarities, axis = 1)\n",
    "\n",
    "  # cos similarity between novel essay and its corresponding prompt\n",
    "  prompt_cos = np.diag(cosine_similarity(novel_essays, novel_essays_prompt))\n",
    "\n",
    "  z_scores_max_cos_sim = calculate_z_scores(max_cos_sim, mean_max_cos_sim, std_dev_max_cos_sim)\n",
    "  z_scores_prompt_cos = calculate_z_scores(prompt_cos, mean_prompt_cos, std_dev_prompt_cos)\n",
    "\n",
    "  return z_scores_max_cos_sim, z_scores_prompt_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# stores mean and std_dev\n",
    "# cos similarities between each training essays with the training set\n",
    "\n",
    "X_train, X_valid, y_train, y_valid= train_test_split(data_vecs, prompt, test_size=0.05, random_state=42)\n",
    "y_valid = np.array(y_valid)\n",
    "\n",
    "true = y_valid.copy()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(y_valid)\n",
    "\n",
    "true = [1 if true[i] == y_valid[i] else 0 for i in range(y_valid.shape[0])]\n",
    "\n",
    "max_cos_sim1 = np.max(cosine_similarity(X_train, X_train), axis = 1)\n",
    "# cos similarity between training essays and its corresponding prompt\n",
    "prompt_similarities = np.diag(cosine_similarity(X_train, prompt_vector[y_train - 1]))\n",
    "\n",
    "# z score parameters\n",
    "mean_max_cos_sim = np.mean(max_cos_sim1)\n",
    "std_dev_max_cos_sim = np.std(max_cos_sim1)\n",
    "# mean_max_cos_sim = np.median(max_cos_sim1)\n",
    "# std_dev_max_cos_sim = (np.percentile(max_cos_sim1, 75) - np.percentile(max_cos_sim1, 25)) / 1.349\n",
    "\n",
    "mean_prompt_cos = np.mean(prompt_similarities)\n",
    "std_dev_prompt_cos = np.std(prompt_similarities)\n",
    "# mean_prompt_cos = np.median(prompt_similarities)\n",
    "# std_dev_prompt_cos = (np.percentile(prompt_similarities, 75) - np.percentile(prompt_similarities, 25)) / 1.349\n",
    "\n",
    "max_cos_sim = np.max(cosine_similarity(X_valid, X_train), axis = 1)\n",
    "\n",
    "# cos similarity between novel essay and its corresponding prompt\n",
    "prompt_cos = np.diag(cosine_similarity(X_valid, prompt_vector[y_valid - 1]))\n",
    "\n",
    "z_scores = []\n",
    "z_scores.append(calculate_z_scores(max_cos_sim, mean_max_cos_sim, std_dev_max_cos_sim))\n",
    "z_scores.append(calculate_z_scores(prompt_cos, mean_prompt_cos, std_dev_prompt_cos))\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, threshold = roc_curve(true, z_scores[0])\n",
    "fpr1, tpr1, threshold1 = roc_curve(true, z_scores[1])\n",
    "opt_threshold1 = threshold1[np.argmax(tpr1 - fpr1)]\n",
    "opt_threshold = threshold[np.argmax(tpr - fpr)]\n",
    "print(opt_threshold, opt_threshold1)\n",
    "# accuracy, confusion matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "pred = [1 if z_scores[0][i] > opt_threshold and z_scores[1][i] > opt_threshold1 else 0 for i in range(len(z_scores[0]))]\n",
    "print(accuracy_score(true, pred))\n",
    "print(confusion_matrix(true, pred))\n",
    "\n",
    "# stores mean and std_dev in a csv file\n",
    "precompute = pd.DataFrame({'mean_max_cos_sim': [mean_max_cos_sim], 'std_dev_max_cos_sim': [std_dev_max_cos_sim], 'mean_prompt_cos': [mean_prompt_cos], 'std_dev_prompt_cos': [std_dev_prompt_cos]})\n",
    "precompute.to_csv(os.path.join(SAVE_DIR, 'precompute.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649,) (649,)\n"
     ]
    }
   ],
   "source": [
    "z_scores= modelA(X_valid, prompt_vector[y_valid - 1])\n",
    "print(z_scores[0].shape, z_scores[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-28524317292836.273\n",
      "-0.08908073589062888\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix, roc curve, accuracy\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, roc_curve, auc, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(true, z_scores[0])\n",
    "fpr1, tpr1, threshold1 = roc_curve(true, z_scores[1])\n",
    "# find threshold\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = threshold[optimal_idx]\n",
    "print(optimal_threshold)\n",
    "optimal_idx1 = np.argmax(tpr1 - fpr1)\n",
    "optimal_threshold1 = threshold1[optimal_idx1]\n",
    "print(optimal_threshold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[561   1]\n",
      " [ 74  13]]\n",
      "0.884437596302003\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix, accuracy\n",
    "pred = [1 if i >= optimal_threshold and j >= optimal_threshold1 else 0 for i, j in zip(z_scores[0], z_scores[1])]\n",
    "print(confusion_matrix(true, pred))\n",
    "print(accuracy_score(true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-36593194584319.57 0.47074779756973545\n",
      "[[556   6]\n",
      " [ 75  12]]\n",
      "0.8751926040061633\n"
     ]
    }
   ],
   "source": [
    "# threshold using percentile\n",
    "percentile = 85\n",
    "threshold2 = np.percentile(z_scores[0], percentile)\n",
    "threshold3 = np.percentile(z_scores[1], percentile)\n",
    "print(threshold2, threshold3)\n",
    "\n",
    "# confusion matrix, accuracy\n",
    "pred = [1 if i >= threshold2 and j >= threshold3 else 0 for i, j in zip(z_scores[0], z_scores[1])]\n",
    "print(confusion_matrix(true, pred))\n",
    "print(accuracy_score(true, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
